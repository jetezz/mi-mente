# ğŸ§  Hybrid Brain: Documento Maestro de IngenierÃ­a

> **VisiÃ³n:** Un "Segundo Cerebro" automatizado que ingiere contenido multimedia (YouTube/Instagram), lo procesa con IA local/hÃ­brida y lo organiza estructuradamente en Notion para consultas futuras (RAG).

---

## 1. Arquitectura de Sistemas (HÃ­brida)

Utilizamos un patrÃ³n de **Microservicios HÃ­bridos** para maximizar rendimiento y eficiencia, orquestados vÃ­a **Docker**.

| Servicio | Rol | TecnologÃ­a | Responsabilidad Principal |
| :--- | :--- | :--- | :--- |
| **Frontend** | Interfaz | **Astro 5 + React** | SSR para dashboard, Static para landing. UI rÃ¡pida y SEO-friendly. |
| **Orquestador** | Cerebro | **Bun + ElysiaJS** | I/O intensivo, LÃ³gica de Negocio, GestiÃ³n de IA (Groq/Cerebras), ConexiÃ³n Notion. |
| **Worker** | MÃºsculo | **Python + FastAPI** | Tareas CPU-bound: Descarga de video (`yt-dlp`), Audio (`ffmpeg`), TranscripciÃ³n (`faster-whisper`). |
| **Base de Datos** | Memoria | **Supabase** | Auth, PostgreSQL (Usuarios, CategorÃ­as JerÃ¡rquicas). |

---

## 2. Estructura del Monorepo (SOLID & Clean Architecture)

El proyecto sigue una estructura **Clean Architecture** estricta para garantizar escalabilidad.

```text
/mi-cerebro
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de todos los servicios
â”œâ”€â”€ .env                        # Variables de entorno globales
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/                    # [Frontend: Astro]
â”‚   â”‚   â”œâ”€â”€ src/components/     # UI Components
â”‚   â”‚   â”œâ”€â”€ src/pages/          # Rutas dashboard/
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ api-bun/                # [Backend A: Orquestador]
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ domain/         # Entidades del negocio (User, Note)
â”‚   â”‚   â”‚   â”œâ”€â”€ application/    # Casos de uso (ProcessUrl, AskBrain)
â”‚   â”‚   â”‚   â””â”€â”€ infrastructure/ # Implementaciones (NotionApi, GroqClient)
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â””â”€â”€ worker-py/              # [Backend B: Procesamiento]
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ services/       # LÃ³gica aislada (YoutubeDownloader, WhisperTranscriber)
â”‚       â”‚   â””â”€â”€ api/            # Endpoints FastAPI
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## 3. Plan de Desarrollo e ImplementaciÃ³n

### ğŸš© Fase 1: Infraestructura y Docker (La Base)
*Objetivo: Tener los 3 servicios corriendo y "hablando" entre sÃ­.*

**Archivos Clave de ConfiguraciÃ³n:**

#### A. `docker-compose.yml` (Orquestador)
Define la red interna y volÃºmenes persistentes.

```yaml
version: '3.8'
services:
  # 1. Worker (Python): Descargas e IA Local
  worker-py:
    build: ./apps/worker-py
    container_name: brain-worker
    restart: always
    volumes:
      - ./apps/worker-py/models:/root/.cache/huggingface # Persistir modelos Whisper
    networks:
      - brain-network

  # 2. API (Bun): LÃ³gica y ConexiÃ³n Externa
  api-bun:
    build: ./apps/api-bun
    container_name: brain-api
    restart: always
    ports:
      - "3000:3000"
    environment:
      - WORKER_URL=http://worker-py:8000 # DNS interno de Docker
    depends_on:
      - worker-py
    networks:
      - brain-network
    
  # 3. Frontend (Astro)
  web:
    build: ./apps/web
    container_name: brain-web
    ports:
      - "4321:4321"
    networks:
      - brain-network

networks:
  brain-network:
    driver: bridge
```

#### B. Dockerfiles EspecÃ­ficos

*   **Worker Python (`apps/worker-py/Dockerfile`):**
    *   **Base:** `python:3.10-slim`
    *   **Clave:** Instalar `ffmpeg` (esencial para `yt-dlp` y audio).
    *   **Comando:** `uvicorn main:app --host 0.0.0.0 --port 8000`

*   **API Bun (`apps/api-bun/Dockerfile`):**
    *   **Base:** `oven/bun:1`
    *   **Comando:** `bun src/index.ts`

---

### ğŸ§ Fase 2: El Worker de Python (Los OÃ­dos)
*Objetivo: API que recibe URL y devuelve Texto Transcrito.*

**TecnologÃ­as:** `FastAPI`, `faster-whisper`, `yt-dlp`, `instaloader`.

1.  **Endpoint**: `POST /transcribe`
2.  **LÃ³gica YouTube**:
    *   Usar `yt-dlp` para extraer solo audio (formato liviano).
    *   Procesar con `faster-whisper` (modelo `small` o `medium` para balance calidad/velocidad).
3.  **LÃ³gica Instagram (Reto TÃ©cnico)**:
    *   Instagram bloquea scrapers.
    *   **SoluciÃ³n Pro:** Exportar cookies de sesiÃ³n del navegador (`instaloader --login user`) a un archivo y montarlo en el contenedor de Python para autenticar las peticiones.

---

### ğŸ§  Fase 3: El Orquestador Bun (El Cerebro)
*Objetivo: LÃ³gica de IA econÃ³mica y conexiÃ³n a Notion.*

**TecnologÃ­as:** `ElysiaJS`, `@notionhq/client`.

1.  **Estrategia "IA Round-Robin" (Midudev Style)**:
    *   No depender de un solo proveedor.
    *   Crear un servicio agnÃ³stico que rote entre **Groq** (Llama 3 70B - Muy rÃ¡pido) y **Cerebras**.
    *   Si uno falla o llega al rate-limit, cambiar al otro automÃ¡ticamente.
2.  **GestiÃ³n de Notion**:
    *   **Input**: Recibir texto plano del Worker y `categoryId`.
    *   **Processing**: Usar la IA para generar: Resumen, Puntos Clave, Etiquetas y Sentimiento.
    *   **Output**: Crear pÃ¡gina en base de datos Notion con formato rico (H1, Bullet points) y asignar la propiedad de CategorÃ­a seleccionada.
3.  **GestiÃ³n de CategorÃ­as**:
    *   CRUD de CategorÃ­as en Supabase con soporte de jerarquÃ­a (`parent_id`).
    *   SincronizaciÃ³n de nombres de categorÃ­as con Notion (opcional, si se usa Select).

---

### ğŸ¨ Fase 4: Frontend Astro (La Interfaz)
*Objetivo: UX simple y directa.*

**TecnologÃ­as:** `Astro`, `React`, `TailwindCSS`.

1.  **Dashboard**:
    *   Status de servicios (Health check a API y Worker).
    *   Selector de **CategorÃ­a** (cargado desde Supabase).
    *   Input "Pegar Link".
    *   Barra de progreso (Descargando -> Transcribiendo -> Resumiendo -> Guardado).
3.  **Admin de CategorÃ­as**:
    *   Interfaz para crear/editar categorÃ­as y definir dependencias (Padre -> Hijo).
2.  **Auth**: Middleware de Astro con Supabase Auth Helpers.

---

### ï¿½ Fase 5: RAG (Chat con tu Segundo Cerebro)
*Objetivo: Preguntar "Â¿QuÃ© vi sobre arquitectura?" y responder con datos frescos de Notion.*

1.  **RecuperaciÃ³n de Contexto (Live)**:
    *   **Input**: Pregunta + `categoryId`.
    *   **Retrieval**:
        1.  Obtener ID de categorÃ­a y sus hijas desde Supabase.
        2.  Consultar API de Notion: Buscar pÃ¡ginas filtradas por esas CategorÃ­as.
        3.  Descargar contenido (bloques de texto) de las pÃ¡ginas encontradas.
    *   **Generation**:
        *   Limpiar y concatenar texto.
        *   Enviar como "Contexto" al LLM (Groq/Cerebras) junto con la pregunta.
        *   *Nota: Se aprovecha la gran ventana de contexto de los modelos actuales (Llama 3, etc) para evitar bases de datos vectoriales complejas al inicio.*

---

## 4. GuÃ­a de Comandos RÃ¡pidos

**Setup Inicial:**
```bash
# Crear estructura
mkdir -p apps/web apps/api-bun apps/worker-py

# Python Worker Deps
# apps/worker-py/requirements.txt
fastapi
uvicorn
yt-dlp
faster-whisper
instaloader
torch

# Bun Deps
cd apps/api-bun
bun add elysia @notionhq/client @supabase/supabase-js

# Levantar Todo
docker-compose up --build
docker-compose down && docker-compose up --build
docker-compose restart

docker builder prune -f && \
docker-compose build --no-cache web && \
docker-compose up --build

docker-compose logs -f

# para resetear variables de entorno
docker-compose down && docker-compose up -d
```

**Referencias y Recursos:**
*   **Video Midudev:** ImplementaciÃ³n de rotaciÃ³n de claves API para IA gratuita.
*   **Faster-Whisper:** [GitHub](https://github.com/SYSTRAN/faster-whisper)
*   **Astro + Supabase:** GuÃ­as oficiales de integraciÃ³n SSR.

---

## ğŸ”® Fase 6: Motor de BÃºsqueda SemÃ¡ntica (Vectores en Supabase)

> **VisiÃ³n:** Notion NO debe ser tu motor de bÃºsqueda. Supabase SÃ debe ser tu motor de recuperaciÃ³n semÃ¡ntica. La IA solo debe ver contexto ya filtrado.

**Flujo Principal:**
```
Notion â†’ IndexaciÃ³n â†’ Supabase Vectorial â†’ Query â†’ IA â†’ (opcional) Notion
```

---

### 6.1 Estructura de Datos Vectorial en Supabase

**ExtensiÃ³n requerida:**
```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

#### A. Tabla `notion_pages` (Metadata)
Contiene metadata de la pÃ¡gina, NO texto largo.

```sql
CREATE TABLE notion_pages (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE NOT NULL,
  notion_page_id TEXT UNIQUE NOT NULL,
  title TEXT,
  category_id UUID REFERENCES categories(id) ON DELETE SET NULL,
  summary TEXT,
  last_edited_time TIMESTAMP,
  created_at TIMESTAMP DEFAULT NOW()
);
```

**Responsabilidad:**
- Identificar la pÃ¡gina original en Notion
- Clasificar por categorÃ­a
- Facilitar filtros previos al bÃºsqueda vectorial

#### B. Tabla `notion_page_chunks` (Contenido Vectorizado)
AquÃ­ vive el contenido fragmentado y sus embeddings.

```sql
CREATE TABLE notion_page_chunks (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  page_id UUID REFERENCES notion_pages(id) ON DELETE CASCADE,
  chunk_index INT,
  content TEXT NOT NULL,
  embedding VECTOR(1536), -- OpenAI ada-002 o similar
  created_at TIMESTAMP DEFAULT NOW()
);
```

**Ãndice vectorial (CRÃTICO para performance):**
```sql
CREATE INDEX ON notion_page_chunks
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

#### C. Por quÃ© esta estructura
- **SeparaciÃ³n documento/fragmentos:** Permite reindexar chunks sin tocar metadata
- **Filtros previos:** Puedes filtrar por `category_id` antes de buscar vectorialmente
- **Escalabilidad:** Compatible con miles de pÃ¡ginas
- **AgnÃ³stico al modelo:** Funciona con cualquier proveedor de embeddings

---

### 6.2 Pipeline de IndexaciÃ³n (OFFLINE)

> âš ï¸ Este proceso NO ocurre cuando el usuario pregunta. Es un job en background.

**Flujo:**
```
Notion API â†’ Texto â†’ Chunking â†’ Embeddings â†’ Supabase (pages + chunks)
```

#### Paso 1: Leer pÃ¡ginas desde Notion
```typescript
// Obtener pÃ¡gina con ID, tÃ­tulo y bloques
const page = await notion.pages.retrieve({ page_id });
const blocks = await notion.blocks.children.list({ block_id: page_id });
```

#### Paso 2: Normalizar contenido
- Convertir bloques Notion â†’ texto plano estructurado
- Eliminar: Headers redundantes, elementos decorativos
- Mantener: PÃ¡rrafos, listas, subtÃ­tulos

#### Paso 3: Chunking
Dividir el texto en fragmentos de:
- **300â€“800 tokens** por chunk
- Solape opcional: 50 tokens (para contexto)

```typescript
const chunks = splitIntoChunks(normalizedText, {
  maxTokens: 600,
  overlap: 50
});
```

#### Paso 4: Generar Embeddings
Para cada chunk:
```typescript
const embedding = await openai.embeddings.create({
  model: "text-embedding-ada-002",
  input: chunk.content
});
```

**Alternativas gratuitas:**
- Groq (si disponible)
- Sentence-Transformers local
- Cohere Embed

#### Paso 5: Persistir en Supabase
```typescript
// Upsert pÃ¡gina
await supabase.from('notion_pages').upsert({
  notion_page_id: page.id,
  title: page.properties.Name,
  category_id,
  summary: generatedSummary
});

// Insertar chunks
await supabase.from('notion_page_chunks').insert(
  chunks.map((chunk, i) => ({
    page_id: notionPage.id,
    chunk_index: i,
    content: chunk.text,
    embedding: chunk.embedding
  }))
);
```

**Resultado:** Supabase queda como Ã­ndice semÃ¡ntico persistente.

---

### 6.3 Pipeline de RecuperaciÃ³n (QUERY TIME)

> âœ… Este flujo SÃ ocurre cuando el usuario pregunta.

**Flujo:**
```
Pregunta usuario â†’ Embedding â†’ BÃºsqueda vectorial Supabase â†’ Contexto relevante â†’ IA
```

#### Paso 1: Embedding de la pregunta
```typescript
const questionEmbedding = await embed(userQuestion);
```

#### Paso 2: BÃºsqueda vectorial en Supabase
```sql
SELECT
  npc.content,
  np.title,
  np.notion_page_id,
  1 - (npc.embedding <=> :question_embedding) AS similarity
FROM notion_page_chunks npc
JOIN notion_pages np ON np.id = npc.page_id
WHERE np.category_id IN (:category_ids) -- Filtro opcional por categorÃ­a
ORDER BY npc.embedding <=> :question_embedding
LIMIT 5;
```

**Nota:** `<=>` es el operador de distancia coseno en pgvector.

#### Paso 3: ConstrucciÃ³n del contexto
```typescript
const context = relevantChunks
  .map(chunk => `## ${chunk.title}\n${chunk.content}`)
  .join('\n\n---\n\n');
```

#### Paso 4: Llamada a la IA
```typescript
const response = await llm.chat({
  system: `Responde basÃ¡ndote ÃšNICAMENTE en el siguiente contexto:\n\n${context}`,
  user: userQuestion
});
```

**La IA recibe:**
- âœ… Pregunta
- âœ… Contexto filtrado y relevante

**La IA NUNCA recibe:**
- âŒ Todas las pÃ¡ginas
- âŒ Notion completo

---

### 6.4 ComunicaciÃ³n con Notion (CuÃ¡ndo y Por QuÃ©)

#### âŒ CuÃ¡ndo NO llamar a Notion
- Para responder preguntas
- Para buscar informaciÃ³n
- Para ranking semÃ¡ntico

> Eso ya lo hace Supabase vectorial.

#### âœ… CuÃ¡ndo SÃ llamar a Notion

**Caso 1: Mostrar pÃ¡gina original**
DespuÃ©s de responder, ofrecer link a la fuente:
```typescript
const notionUrl = `https://notion.so/${notionPageId.replace(/-/g, '')}`;
```

**Caso 2: ActualizaciÃ³n de contenido (Re-indexaciÃ³n)**
Disparadores:
- Webhook de Notion (cambio detectado)
- Cron job programado
- BotÃ³n manual en dashboard

```
Notion cambia â†’ Reindexar pÃ¡gina â†’ Actualizar embeddings en Supabase
```

**Caso 3: RecuperaciÃ³n completa bajo demanda**
Si el usuario pide: "MuÃ©strame el documento completo"
- Sabemos quÃ© pÃ¡gina es (tenemos `notion_page_id`)
- La traemos de Notion directamente
- La mostramos (NO la pasamos a la IA)

---

### 6.5 Diagrama de Flujos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INDEXACIÃ“N (Offline)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Notion API â”€â”€â–º Texto â”€â”€â–º Chunks â”€â”€â–º Embeddings         â”‚
â”‚                                         â”‚               â”‚
â”‚                                         â–¼               â”‚
â”‚                                    Supabase             â”‚
â”‚                              (pages + chunks)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RECUPERACIÃ“N (Query)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Usuario â”€â”€â–º Embedding â”€â”€â–º BÃºsqueda Vectorial           â”‚
â”‚                                   â”‚                     â”‚
â”‚                                   â–¼                     â”‚
â”‚                          Top-K Chunks                   â”‚
â”‚                                   â”‚                     â”‚
â”‚                                   â–¼                     â”‚
â”‚                     Contexto â”€â”€â–º LLM â”€â”€â–º Respuesta      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMUNICACIÃ“N CON NOTION                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Supabase identifica pÃ¡gina                             â”‚
â”‚         â”‚                                               â”‚
â”‚         â”œâ”€â”€â–º Mostrar link original                      â”‚
â”‚         â”œâ”€â”€â–º Re-indexar si hay cambios                  â”‚
â”‚         â””â”€â”€â–º Recuperar documento completo (bajo demanda)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 6.6 ConclusiÃ³n TÃ©cnica

| Componente | Rol |
|------------|-----|
| **Supabase** | Motor semÃ¡ntico (vectores) |
| **Notion** | Fuente de verdad (datos originales) |
| **IA** | Razonador, NO buscador |
| **VectorizaciÃ³n** | Proceso offline |
| **Query** | Ligero y rÃ¡pido |

**Beneficios de esta arquitectura:**
- âœ… Escala a miles de documentos
- âœ… Reduce costos de API
- âœ… Mejora precisiÃ³n de recuperaciÃ³n
- âœ… Evita dependencias innecesarias de Notion en tiempo real

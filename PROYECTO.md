# üß† Hybrid Brain: Documento Maestro de Ingenier√≠a

> **Visi√≥n:** Un "Segundo Cerebro" automatizado que ingiere contenido multimedia (YouTube/Instagram), lo procesa con IA local/h√≠brida y lo organiza estructuradamente en Notion para consultas futuras (RAG).

---

## 1. Arquitectura de Sistemas (H√≠brida)

Utilizamos un patr√≥n de **Microservicios H√≠bridos** para maximizar rendimiento y eficiencia, orquestados v√≠a **Docker**.

| Servicio | Rol | Tecnolog√≠a | Responsabilidad Principal |
| :--- | :--- | :--- | :--- |
| **Frontend** | Interfaz | **Astro 5 + React** | SSR para dashboard, Static para landing. UI r√°pida y SEO-friendly. |
| **Orquestador** | Cerebro | **Bun + ElysiaJS** | I/O intensivo, L√≥gica de Negocio, Gesti√≥n de IA (Groq/Cerebras), Conexi√≥n Notion. |
| **Worker** | M√∫sculo | **Python + FastAPI** | Tareas CPU-bound: Descarga de video (`yt-dlp`), Audio (`ffmpeg`), Transcripci√≥n (`faster-whisper`). |
| **Base de Datos** | Memoria | **Supabase** | Auth, PostgreSQL (Usuarios, Categor√≠as Jer√°rquicas). |

---

## 2. Estructura del Monorepo (SOLID & Clean Architecture)

El proyecto sigue una estructura **Clean Architecture** estricta para garantizar escalabilidad.

```text
/mi-cerebro
‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestaci√≥n de todos los servicios
‚îú‚îÄ‚îÄ .env                        # Variables de entorno globales
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ web/                    # [Frontend: Astro]
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/components/     # UI Components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/pages/          # Rutas dashboard/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api-bun/                # [Backend A: Orquestador]
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain/         # Entidades del negocio (User, Note)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ application/    # Casos de uso (ProcessUrl, AskBrain)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/ # Implementaciones (NotionApi, GroqClient)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ worker-py/              # [Backend B: Procesamiento]
‚îÇ       ‚îú‚îÄ‚îÄ app/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ services/       # L√≥gica aislada (YoutubeDownloader, WhisperTranscriber)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ api/            # Endpoints FastAPI
‚îÇ       ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ       ‚îî‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ README.md
```

---

## 3. Plan de Desarrollo e Implementaci√≥n

### üö© Fase 1: Infraestructura y Docker (La Base)
*Objetivo: Tener los 3 servicios corriendo y "hablando" entre s√≠.*

**Archivos Clave de Configuraci√≥n:**

#### A. `docker-compose.yml` (Orquestador)
Define la red interna y vol√∫menes persistentes.

```yaml
version: '3.8'
services:
  # 1. Worker (Python): Descargas e IA Local
  worker-py:
    build: ./apps/worker-py
    container_name: brain-worker
    restart: always
    volumes:
      - ./apps/worker-py/models:/root/.cache/huggingface # Persistir modelos Whisper
    networks:
      - brain-network

  # 2. API (Bun): L√≥gica y Conexi√≥n Externa
  api-bun:
    build: ./apps/api-bun
    container_name: brain-api
    restart: always
    ports:
      - "3000:3000"
    environment:
      - WORKER_URL=http://worker-py:8000 # DNS interno de Docker
    depends_on:
      - worker-py
    networks:
      - brain-network
    
  # 3. Frontend (Astro)
  web:
    build: ./apps/web
    container_name: brain-web
    ports:
      - "4321:4321"
    networks:
      - brain-network

networks:
  brain-network:
    driver: bridge
```

#### B. Dockerfiles Espec√≠ficos

*   **Worker Python (`apps/worker-py/Dockerfile`):**
    *   **Base:** `python:3.10-slim`
    *   **Clave:** Instalar `ffmpeg` (esencial para `yt-dlp` y audio).
    *   **Comando:** `uvicorn main:app --host 0.0.0.0 --port 8000`

*   **API Bun (`apps/api-bun/Dockerfile`):**
    *   **Base:** `oven/bun:1`
    *   **Comando:** `bun src/index.ts`

---

### üéß Fase 2: El Worker de Python (Los O√≠dos)
*Objetivo: API que recibe URL y devuelve Texto Transcrito.*

**Tecnolog√≠as:** `FastAPI`, `faster-whisper`, `yt-dlp`, `instaloader`.

1.  **Endpoint**: `POST /transcribe`
2.  **L√≥gica YouTube**:
    *   Usar `yt-dlp` para extraer solo audio (formato liviano).
    *   Procesar con `faster-whisper` (modelo `small` o `medium` para balance calidad/velocidad).
3.  **L√≥gica Instagram (Reto T√©cnico)**:
    *   Instagram bloquea scrapers.
    *   **Soluci√≥n Pro:** Exportar cookies de sesi√≥n del navegador (`instaloader --login user`) a un archivo y montarlo en el contenedor de Python para autenticar las peticiones.

---

### üß† Fase 3: El Orquestador Bun (El Cerebro)
*Objetivo: L√≥gica de IA econ√≥mica y conexi√≥n a Notion.*

**Tecnolog√≠as:** `ElysiaJS`, `@notionhq/client`.

1.  **Estrategia "IA Round-Robin" (Midudev Style)**:
    *   No depender de un solo proveedor.
    *   Crear un servicio agn√≥stico que rote entre **Groq** (Llama 3 70B - Muy r√°pido) y **Cerebras**.
    *   Si uno falla o llega al rate-limit, cambiar al otro autom√°ticamente.
2.  **Gesti√≥n de Notion**:
    *   **Input**: Recibir texto plano del Worker y `categoryId`.
    *   **Processing**: Usar la IA para generar: Resumen, Puntos Clave, Etiquetas y Sentimiento.
    *   **Output**: Crear p√°gina en base de datos Notion con formato rico (H1, Bullet points) y asignar la propiedad de Categor√≠a seleccionada.
3.  **Gesti√≥n de Categor√≠as**:
    *   CRUD de Categor√≠as en Supabase con soporte de jerarqu√≠a (`parent_id`).
    *   Sincronizaci√≥n de nombres de categor√≠as con Notion (opcional, si se usa Select).

---

### üé® Fase 4: Frontend Astro (La Interfaz)
*Objetivo: UX simple y directa.*

**Tecnolog√≠as:** `Astro`, `React`, `TailwindCSS`.

1.  **Dashboard**:
    *   Status de servicios (Health check a API y Worker).
    *   Selector de **Categor√≠a** (cargado desde Supabase).
    *   Input "Pegar Link".
    *   Barra de progreso (Descargando -> Transcribiendo -> Resumiendo -> Guardado).
3.  **Admin de Categor√≠as**:
    *   Interfaz para crear/editar categor√≠as y definir dependencias (Padre -> Hijo).
2.  **Auth**: Middleware de Astro con Supabase Auth Helpers.

---

### ÔøΩ Fase 5: RAG (Chat con tu Segundo Cerebro)
*Objetivo: Preguntar "¬øQu√© vi sobre arquitectura?" y responder con datos frescos de Notion.*

1.  **Recuperaci√≥n de Contexto (Live)**:
    *   **Input**: Pregunta + `categoryId`.
    *   **Retrieval**:
        1.  Obtener ID de categor√≠a y sus hijas desde Supabase.
        2.  Consultar API de Notion: Buscar p√°ginas filtradas por esas Categor√≠as.
        3.  Descargar contenido (bloques de texto) de las p√°ginas encontradas.
    *   **Generation**:
        *   Limpiar y concatenar texto.
        *   Enviar como "Contexto" al LLM (Groq/Cerebras) junto con la pregunta.
        *   *Nota: Se aprovecha la gran ventana de contexto de los modelos actuales (Llama 3, etc) para evitar bases de datos vectoriales complejas al inicio.*

---

## 4. Gu√≠a de Comandos R√°pidos

**Setup Inicial:**
```bash
# Crear estructura
mkdir -p apps/web apps/api-bun apps/worker-py

# Python Worker Deps
# apps/worker-py/requirements.txt
fastapi
uvicorn
yt-dlp
faster-whisper
instaloader
torch

# Bun Deps
cd apps/api-bun
bun add elysia @notionhq/client @supabase/supabase-js

# Levantar Todo
docker-compose up --build
docker-compose down && docker-compose up --build
docker-compose restart

docker builder prune -f && \
docker-compose build --no-cache web && \
docker-compose up --build

docker-compose logs -f
```

**Referencias y Recursos:**
*   **Video Midudev:** Implementaci√≥n de rotaci√≥n de claves API para IA gratuita.
*   **Faster-Whisper:** [GitHub](https://github.com/SYSTRAN/faster-whisper)
*   **Astro + Supabase:** Gu√≠as oficiales de integraci√≥n SSR.
